# RDD-Functions & PySpark SQL Project ğŸš€

This repository contains two Spark-based assessments done as part of learning **Big Data Analytics** with PySpark.

---

## ğŸ“‚ Contents
1. **Assessment 1 - RDD Operations**
   - Load data into RDD  
   - Find the season with the highest and lowest number of goals  
   - Find the team with the highest average goals per season  
   - Calculate probabilities of Manchester United wins, losses, and draws  

   ğŸ‘‰ Implemented using **PySpark RDDs** in Google Colab.

2. **Assessment 2 - PySpark SQL**
   - Used a Kaggle dataset (Football dataset / any suitable dataset)  
   - Loaded data into **Spark DataFrame**  
   - Created SQL queries using `spark.sql()`  
   - Performed filtering, grouping, and aggregations.  

   ğŸ‘‰ Implemented using **PySpark SQL** in Google Colab.

---

## âš™ï¸ Setup Instructions
To run this project in **Google Colab**:
1. Install PySpark:
   ```bash
   !pip install pyspark
2.Upload dataset files to Colab (from Kaggle or local machine).

3.Run the notebook cells step by step.

Tools & Technologies
Python 3
Apache Spark (PySpark)
Google Colab
Kaggle Datasets

Author
Janani Dass
3rd Year Engineering Student | Aspiring Full Stack Developer & Data Engineer
